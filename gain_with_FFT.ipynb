{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_folder = os.path.dirname(os.path.abspath(\"__file__\")) # Gets the location of the present script\n",
    "parent_folder = os.path.dirname(current_folder) # Gets the path for the origin of the repository, as it is locally stored\n",
    "utils_folder = os.path.join(parent_folder, 'utilities') # Creates a view to the utilites the folder\n",
    "os.chdir(utils_folder) # Makes it the active folder\n",
    "from metro_utils import * # Imports everything from metro_utils\n",
    "from rf_utils import * # Imports everything from rf_utils\n",
    "from LabberReader import * # Uncomment if you have access to the Labber API\n",
    "os.chdir(current_folder) # Makes the folder of the script the active one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr #estensione di pandas per lavorare con array multidimensionali\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter, find_peaks, argrelextrema #strumenti per signal processing: Applies a Savitzky-Golay filter to an array, Finds peaks inside a signal based on peak properties, Calculate the relative extrema of data\n",
    "from scipy.optimize import curve_fit #Use non-linear least squares to fit a function, f, to data\n",
    "from scipy.stats import linregress #Calculate a linear least-squares regression for two sets of measurements\n",
    "from typing import Optional #Typing: This module provides runtime support for type hints, Optional: Use Optional to indicate that an object is either one given type or None\n",
    "from itertools import product #provides various functions for creating and manipulating iterators, product: computes the cartesian product of input iterables\n",
    "import matplotlib.patches as patches # Patches are arbitrary two dimensional regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dB(x, n=2):\n",
    "    return n * 10 * np.log10(x)\n",
    "\n",
    "#definisco l'\"inversa\" di db\n",
    "def linear(x, n=1):\n",
    "    return 10**(x / (n * 10))\n",
    "\n",
    "#Definisco l'equazione per una parabola\n",
    "def parabula(x, a, b, c):\n",
    "    x = np.array(x)\n",
    "    return a*x**2 + b*x +c\n",
    "\n",
    "#Definisco la combinazione lineare di due gaussiane di media x1, x2 e std s1, s2\n",
    "def two_gaussians(x, A1, A2, x1, x2, s1, s2):\n",
    "    return A1 * np.exp(-((x-x1)/s1)**2) + A2 * np.exp(-((x-x2)/s2)**2)\n",
    "\n",
    "def padded_moving_average(data, window=11):\n",
    "    #add data outside range to perform moving average on the first and last points\n",
    "    padded_data = np.pad(data, (window//2, window//2), mode='reflect')\n",
    "\n",
    "    #returns the smoothed function\n",
    "    return np.convolve(padded_data, np.ones(window)/window, mode=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_on_diff(profile: xr.core.dataarray.DataArray, \n",
    "                average: np.ndarray):\n",
    "    '''\n",
    "    Function that takes the difference between the original profile and the smoothed one with moving average as input,\n",
    "    computes its fft and returns the fft maximum and its correspondent time in order to choose the best window.\n",
    "    '''\n",
    "    #Calcoliamo la differenza\n",
    "    diff_profile = profile-average\n",
    "\n",
    "    #calcoliamo la trasformata\n",
    "    fft = np.fft.fft(diff_profile)\n",
    "    magnitude = np.abs(fft)\n",
    "\n",
    "    #dare un range per le x\n",
    "    frequencies = np.linspace(0.4e10, 1.2e10, len(diff_profile))\n",
    "    time = frequencies\n",
    "    dt = np.mean(np.diff(time))\n",
    "\n",
    "    fft_frequencies = np.fft.fftfreq(len(diff_profile), d=dt)\n",
    "\n",
    "    #plots\n",
    "    fig, ax = plt.subplots(2, 1, figsize=[10, 5], dpi=200)\n",
    "\n",
    "    #difference plot\n",
    "    ax[0].plot(time, diff_profile, color=\"red\", label=\"Profile minus average\")\n",
    "    ax[0].set_xlabel(\"Frequency (Hz)\") \n",
    "    ax[0].set_ylabel(\"|S21| / dB\")\n",
    "    ax[0].legend()\n",
    "    ax[0].grid()\n",
    "\n",
    "    #fft plot\n",
    "    ax[1].plot(fft_frequencies[fft_frequencies >= 0], \n",
    "            magnitude[fft_frequencies >= 0], \n",
    "            color='blue', label=\"FFT\")\n",
    "    ax[1].set_xlabel(\"Time (s)\")\n",
    "    ax[1].set_ylabel(\"Magnitude\")\n",
    "    ax[1].legend()\n",
    "    ax[1].grid()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #Find maximum\n",
    "    max_fft = np.max(magnitude[fft_frequencies >= 0])\n",
    "    max_time = fft_frequencies[fft_frequencies > 0][np.argmax(magnitude[fft_frequencies >= 0])]\n",
    "    ind_max = np.argmax(magnitude[fft_frequencies >= 0])\n",
    "\n",
    "    print(f'Massimo\\np0: {max_fft}\\nTime: {max_time} s\\nIndice del massimo: {ind_max}')\n",
    "\n",
    "    prop = max_fft/max_time\n",
    "\n",
    "    print(f\"Prodotto = {prop}\\nFreq = {1/max_time} Hz\\n\")\n",
    "\n",
    "    return max_fft, 1/max_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the optimal window width to perform the moving average\n",
    "\n",
    "#Funziona con argo e crescendo, verificare su eventuali altri dispositivi\n",
    "def best_window(p0, frequency, alpha=0.015, step=16e6):\n",
    "    if int(p0*frequency*alpha/step)%2 == 1 and int(p0*frequency*alpha/step) <= 13:\n",
    "        return int(p0*frequency*alpha/step)\n",
    "    elif int(p0*frequency*alpha/step)%2 == 0 and int(p0*frequency*alpha/step)-1 <= 13:\n",
    "        return int(p0*frequency*alpha/step)-1\n",
    "    else:\n",
    "        return 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_G_BW(\n",
    "        x: np.ndarray, # The frequency array\n",
    "        y: np.ndarray, # The trace\n",
    "        phase_matching_scheme: {'Dispersion engineering', 'Reversed Kerr'}, #dispersion engineering è il profilo \"bucato\"\n",
    "        f_p  = None,\n",
    "        w: float = 0.1e9, # The window width (in Hz) for Svaitsky Golay filter\n",
    "        min_prominence=0.1, # Relative minimal prominace of the local minima to be used in the algorithm for locating the stopband\n",
    "        cut_off=None, # An upper cut-off on frequency to avoid pathological behaviour\n",
    "        ):\n",
    "    y = 20*np.log10(np.abs(y))\n",
    "    if cut_off is not None:\n",
    "        x, y = x[x<=cut_off], y[x<=cut_off]\n",
    "    dx = x[1]-x[0]\n",
    "    # limiting the examined region at the actual amplification band\n",
    "    try: #L'istruzione try except mi permette di intercettare uno o più errori nell'esecuzione di un blocco di istruzioni tramite la gestione delle eccezioni\n",
    "        edges = x[y>=0][0], x[y>=0][-1] #considero gli elementi di x in cui y è non negativa e prendo i bordi, dove la traccia è y = 20*np.log10(np.abs(y))\n",
    "    except IndexError:\n",
    "        return 0\n",
    "    amp_x, amp_y = x[x >= edges[0]], y[x >= edges[0]]\n",
    "    amp_x, amp_y = amp_x[amp_x <= edges[-1]], amp_y[amp_x <= edges[-1]] \n",
    "\n",
    "    if phase_matching_scheme == 'Dispersion engineering':\n",
    "\n",
    "        # minima whose prominence is at least 10 % of the whole range of transmission values\n",
    "        min_idxs = find_peaks(-amp_y, prominence=min_prominence*(np.max(amp_y)-np.min(amp_y)))[0]\n",
    "\n",
    "        # the minima laying in region of positive concavity are selected\n",
    "        try:\n",
    "            y_der2 = savgol_filter(amp_y, window_length=int(w / dx), polyorder=2, deriv=2)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "        selected_min_idxs = []\n",
    "        for min_idx in min_idxs:\n",
    "            if np.interp(amp_x[min_idx], amp_x, y_der2) > 0:\n",
    "                selected_min_idxs.append(min_idx)\n",
    "\n",
    "        # the points of change of concavity sign that enclose the selected minima\n",
    "        zeros_indices = np.where(np.diff(y_der2 > 0))[0]\n",
    "        i1 = np.max(zeros_indices[zeros_indices <= np.min(selected_min_idxs)])\n",
    "        i2 = np.min(zeros_indices[zeros_indices >= np.max(selected_min_idxs)])\n",
    "\n",
    "        # The fit will be permormed on a new set of points the bandgap has been excluded from\n",
    "        x_fit, y_fit = np.array([*amp_x[:i1], *amp_x[i2:]]), np.array([*amp_y[:i1], *amp_y[i2:]]) # * usato per passare un numero variabile di argomenti\n",
    "\n",
    "        # I fit the two regions with lines, to find their intersection and use it as a guess on the parabula's vertex\n",
    "        r1 = linregress(amp_x[:i1], amp_y[:i1])\n",
    "        r2 = linregress(amp_x[i2:], amp_y[i2:])\n",
    "        x0 = (r2.intercept - r1.intercept)/(r1.slope-r2.slope)\n",
    "        y0 = r2.slope * x0 + r2.intercept\n",
    "\n",
    "        a = (amp_y[0]-y0)/(amp_x[0]-x0)**2 \n",
    "        b = 2*a*x0\n",
    "        c = y0 + a*x0**2\n",
    "\n",
    "        popt, _ = curve_fit(\n",
    "            parabula, \n",
    "            x_fit, \n",
    "            y_fit, \n",
    "            p0=(a,b,c),\n",
    "            )\n",
    "        \n",
    "        #popt sarà un array. Optimal values for the parameters so that the sum of the squared residuals of f(xdata, *popt) - ydata is minimized.\n",
    "        #_ \n",
    "\n",
    "        # The two gains are the maximum values of the parabula in the two regions\n",
    "        G_LRB = np.max(parabula(amp_x[:i1], *popt))\n",
    "        G_URB = np.max(parabula(amp_x[i2:], *popt))\n",
    "\n",
    "        # The frequency edges of the usable read-out bands are those that keep the transmission above half the quoted gain\n",
    "        f1_LRB = np.max(amp_x[:i1][parabula(amp_x[:i1], *popt) >= G_LRB - 3])\n",
    "        f2_LRB = np.min(amp_x[:i1][parabula(amp_x[:i1], *popt) >= G_LRB - 3])\n",
    "        BW_LRB = np.abs(f2_LRB - f1_LRB)\n",
    "\n",
    "        f1_URB = np.max(amp_x[i2:][parabula(amp_x[i2:], *popt) >= G_URB - 3])\n",
    "        f2_URB = np.min(amp_x[i2:][parabula(amp_x[i2:], *popt) >= G_URB - 3])\n",
    "        BW_URB = np.abs(f2_URB - f1_URB)\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            popt, _ = curve_fit(\n",
    "                two_gaussians, \n",
    "                amp_x, \n",
    "                amp_y, \n",
    "                # bounds=([0,30],[0,30], [4e9, f_p], [f_p, 12e9], [0, 8e9], [0,8e9]),\n",
    "                bounds = ([0,0,4e9,f_p,0,0], [30,30,f_p,12e9, 8e9, 8e9])\n",
    "                )\n",
    "        except RuntimeError:\n",
    "            return -100\n",
    "        \n",
    "        G_LRB, G_URB = popt[0], popt[1]\n",
    "        one_band = False\n",
    "        try:\n",
    "            i_split = argrelextrema(amp_y, np.less)[0][0] #np.less: Return the truth value of (x1 < x2) element-wise\n",
    "        except IndexError:\n",
    "            i_split = len(amp_x)-1\n",
    "            one_band = True\n",
    "\n",
    "        \n",
    "        # The frequency edges of the usable read-out bands are those that keep the transmission above half the quoted gain\n",
    "        f1_LRB = np.max(amp_x[:i_split][two_gaussians(amp_x[:i_split], *popt) >= G_LRB - 3])\n",
    "        f2_LRB = np.min(amp_x[:i_split][two_gaussians(amp_x[:i_split], *popt) >= G_LRB - 3])\n",
    "        BW_LRB = np.abs(f2_LRB - f1_LRB)\n",
    "\n",
    "        if not one_band:\n",
    "            f1_URB = np.max(amp_x[i_split:][two_gaussians(amp_x[i_split:], *popt) >= G_URB - 3])\n",
    "            f2_URB = np.min(amp_x[i_split:][two_gaussians(amp_x[i_split:], *popt) >= G_URB - 3])\n",
    "            BW_URB = np.abs(f2_URB - f1_URB)\n",
    "        else:\n",
    "            BW_URB = 0\n",
    "\n",
    "    metric = (linear(G_LRB)*BW_LRB + linear(G_URB)*BW_URB)/1e9\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GainMap(filename: str, \n",
    "            phase_matching_scheme: {'Dispersion engineering', 'Reversed Kerr'}, \n",
    "            w: float = 0.4e9, \n",
    "            min_prominence: float =0.2, \n",
    "            cut_off: Optional[float] = 10e9, \n",
    "            top_k: int = 5):\n",
    "    ds = xr.open_dataset(filename, engine='h5netcdf')\n",
    "    x = ds['Frequency'].data\n",
    "    y = ds['S21']\n",
    "    figure_of_merit = xr.zeros_like(y.real.mean('Frequency'))\n",
    "    figure_of_merit.attrs = dict(long_name=r'$\\text{GB}_\\text{eff}$', unit='GHz')\n",
    "    for I in product(*[range(size) for size in figure_of_merit.shape]):\n",
    "        local_coords = {coord: figure_of_merit[coord][i] for coord, i in zip(figure_of_merit.coords.keys(), I)}\n",
    "        my_y = y.loc[local_coords].data\n",
    "        \n",
    "        try:\n",
    "            #metric = find_G_BW(x, my_y, w=w, phase_matching_scheme=phase_matching_scheme, f_p=local_coords.get('Pump frequency') if phase_matching_scheme == 'Reversed Kerr' else None, min_prominence=min_prominence, cut_off=cut_off)\n",
    "            metric = np.mean(20*np.log10(np.abs(my_y)))\n",
    "        except ValueError:\n",
    "            metric = 0\n",
    "            # print('hey')\n",
    "        figure_of_merit.loc[{coord: figure_of_merit[coord][i] for coord, i in zip(figure_of_merit.coords.keys(), I)}] = metric\n",
    "\n",
    "    topKperformances = np.sort(figure_of_merit.data, axis=None)[::-1][:top_k]\n",
    "    topKidxs = np.array(np.unravel_index(np.argsort(figure_of_merit.data, axis=None)[::-1][:top_k], figure_of_merit.shape)).T\n",
    "    \n",
    "    topKparameters = []\n",
    "    # print(topKidxs)\n",
    "    \n",
    "    for idxs in topKidxs:\n",
    "        # print(idxs)\n",
    "        topKparameters.append({})\n",
    "        for coord, i in zip(figure_of_merit.coords.keys(), idxs):\n",
    "            topKparameters[-1][str(coord)]=  float(figure_of_merit[coord][i])\n",
    "\n",
    "    \n",
    "    return topKperformances, topKparameters, figure_of_merit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_everything(file_coarse, \n",
    "                    file_fine, \n",
    "                    device_name=None, \n",
    "                    top_k=2, \n",
    "                    eval_func=GainMap, \n",
    "                    **eval_func_kwargs):\n",
    "    max1, best_pump_parameters, figure_of_merit = GainMap(file_coarse, top_k=1, **eval_func_kwargs)\n",
    "    max2, best_pump_parameters2, figure_of_merit2 = GainMap(file_fine, top_k=top_k, **eval_func_kwargs)\n",
    "    S21_fine = xr.open_dataset(file_fine, engine='h5netcdf')['S21'].rf.LogMag()\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=[10, 3], dpi=200)\n",
    "\n",
    "    figure_of_merit.metroplot(vmin=0, vmax=np.fmax(max1[0], max2[0]), cmap='SQE@INRiM', x=str(list(figure_of_merit[0].coords.keys())[0]), ax =ax1)\n",
    "    # ax1.plot([list(best_pump_parameters.values())[0]], [list(best_pump_parameters.values())[1]], 'rx')\n",
    "    xy = list(best_pump_parameters[0].values())[0]-35e6, list(best_pump_parameters[0].values())[1]-2.5\n",
    "    rect = patches.Rectangle(xy, 70e6, 5, linewidth=1, edgecolor='r', facecolor='none', linestyle='--', clip_on=False, alpha=0.75, lw=.75)\n",
    "    ax1.add_patch(rect)\n",
    "    c = figure_of_merit2.metroplot(vmin=0, vmax=np.fmax(max1[0], max2[0]), cmap='SQE@INRiM', x=str(list(figure_of_merit[0].coords.keys())[0]), ax =ax2)\n",
    "    x_coords = c.get_paths()[0].vertices[:, 0]\n",
    "    y_coords = c.get_paths()[0].vertices[:, 1]\n",
    "    pixel_width = np.diff(np.unique(x_coords)).mean()\n",
    "    pixel_height = np.diff(np.unique(y_coords)).mean()\n",
    "    cmap = mpl.colormaps['brg']\n",
    "    colors = cmap(np.linspace(0.5, 1, top_k))\n",
    "    gain_profile = []\n",
    "    mov_avg = []\n",
    "\n",
    "    for max, pump_pars, color in zip(max2, best_pump_parameters2, colors):\n",
    "        xy2 = list(pump_pars.values())[0] - pixel_width/2, list(pump_pars.values())[1] - pixel_height/2\n",
    "        rect2 = plt.Rectangle(\n",
    "            xy2,\n",
    "            pixel_width, \n",
    "            pixel_height, \n",
    "            edgecolor=color, \n",
    "            facecolor='none', \n",
    "            linewidth=.75,\n",
    "            alpha=.75\n",
    "            )\n",
    "        ax2.add_patch(rect2)\n",
    "\n",
    "        label = figure_of_merit2[0].attrs['long_name'] + f' = {max:.2f} GHz with '\n",
    "        for key, val in pump_pars.items():\n",
    "            label += f'{val:.5g} {figure_of_merit2[0][key].attrs[\"unit\"]}, '\n",
    "        # print(pump_pars)\n",
    "        S21_fine.sel(pump_pars).metroplot(ax=ax3, color=color, label=label[:-2], lw=0.7) #Return a new DataArray whose data is given by selecting index labels along the specified dimension(s).\n",
    "        #ax3.plot(S21_fine[\"Frequency\"].data, padded_moving_average(S21_fine.sel(pump_pars)), label=\"MA\") #sistemare label\n",
    "        gain_profile.append(S21_fine.sel(pump_pars))\n",
    "        mov_avg.append(padded_moving_average(S21_fine.sel(pump_pars)))\n",
    "    \n",
    "    ax3.legend(loc='lower center', bbox_to_anchor=(0.5, 1))\n",
    "    ax3.grid()\n",
    "    ax3.set_title('')\n",
    "   \n",
    "    if device_name is not None:\n",
    "        ax2.set_title(device_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.subplots(figsize=[10, 3], dpi=200)\n",
    "    for i, color in zip(range(len(mov_avg)), colors):\n",
    "        plt.plot(S21_fine[\"Frequency\"].data, mov_avg[i], color=color, label=f'MA profilo {i+1}')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Frequency / Hz\")\n",
    "    plt.ylabel(\"|S21| / dB\")\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Moving Average for each Profile\")\n",
    "    \n",
    "    for j in range(len(best_pump_parameters2)):\n",
    "        print(f'List of parameters {j+1}: {best_pump_parameters2[j]}')\n",
    "    return best_pump_parameters2, gain_profile, mov_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'c:\\Users\\Mattia\\OneDrive\\Documenti\\GitHub\\Data_Analysis\\Data\\ARGO SW2311019A - Coarse gain tune up.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key]\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[key]\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'h5netcdf.core.File'>, ('c:\\\\Users\\\\Mattia\\\\OneDrive\\\\Documenti\\\\GitHub\\\\Data_Analysis\\\\Data\\\\ARGO SW2311019A - Coarse gain tune up.h5',), 'r', (('decode_vlen_strings', True), ('invalid_netcdf', None)), '12e8db0c-55ed-4e6b-a6e7-34c4cedb2eec']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pump_pars, g_prof, m_avg \u001b[38;5;241m=\u001b[39m plot_everything(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/ARGO SW2311019A - Coarse gain tune up.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/ARGO SW2311019A - Fine gain tune up.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARGO SW2311019A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      5\u001b[0m     phase_matching_scheme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDispersion engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      6\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4e9\u001b[39m, min_prominence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, cut_off\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e9\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mplot_everything\u001b[1;34m(file_coarse, file_fine, device_name, top_k, eval_func, **eval_func_kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_everything\u001b[39m(file_coarse, \n\u001b[0;32m      2\u001b[0m                     file_fine, \n\u001b[0;32m      3\u001b[0m                     device_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m      4\u001b[0m                     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[0;32m      5\u001b[0m                     eval_func\u001b[38;5;241m=\u001b[39mGainMap, \n\u001b[0;32m      6\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_func_kwargs):\n\u001b[1;32m----> 7\u001b[0m     max1, best_pump_parameters, figure_of_merit \u001b[38;5;241m=\u001b[39m GainMap(file_coarse, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_func_kwargs)\n\u001b[0;32m      8\u001b[0m     max2, best_pump_parameters2, figure_of_merit2 \u001b[38;5;241m=\u001b[39m GainMap(file_fine, top_k\u001b[38;5;241m=\u001b[39mtop_k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_func_kwargs)\n\u001b[0;32m      9\u001b[0m     S21_fine \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(file_fine, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS21\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrf\u001b[38;5;241m.\u001b[39mLogMag()\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mGainMap\u001b[1;34m(filename, phase_matching_scheme, w, min_prominence, cut_off, top_k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGainMap\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, \n\u001b[0;32m      2\u001b[0m             phase_matching_scheme: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDispersion engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReversed Kerr\u001b[39m\u001b[38;5;124m'\u001b[39m}, \n\u001b[0;32m      3\u001b[0m             w: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4e9\u001b[39m, \n\u001b[0;32m      4\u001b[0m             min_prominence: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[0;32m      5\u001b[0m             cut_off: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10e9\u001b[39m, \n\u001b[0;32m      6\u001b[0m             top_k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(filename, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m      9\u001b[0m     y \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS21\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\api.py:566\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    555\u001b[0m     decode_cf,\n\u001b[0;32m    556\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 566\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    567\u001b[0m     filename_or_obj,\n\u001b[0;32m    568\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    572\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[0;32m    573\u001b[0m     backend_ds,\n\u001b[0;32m    574\u001b[0m     filename_or_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    585\u001b[0m )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\h5netcdf_.py:413\u001b[0m, in \u001b[0;36mH5netcdfBackendEntrypoint.open_dataset\u001b[1;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, format, group, lock, invalid_netcdf, phony_dims, decode_vlen_strings)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    396\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     decode_vlen_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[0;32m    412\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m--> 413\u001b[0m     store \u001b[38;5;241m=\u001b[39m H5NetCDFStore\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m    414\u001b[0m         filename_or_obj,\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    416\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    417\u001b[0m         lock\u001b[38;5;241m=\u001b[39mlock,\n\u001b[0;32m    418\u001b[0m         invalid_netcdf\u001b[38;5;241m=\u001b[39minvalid_netcdf,\n\u001b[0;32m    419\u001b[0m         phony_dims\u001b[38;5;241m=\u001b[39mphony_dims,\n\u001b[0;32m    420\u001b[0m         decode_vlen_strings\u001b[38;5;241m=\u001b[39mdecode_vlen_strings,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    423\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[0;32m    425\u001b[0m     ds \u001b[38;5;241m=\u001b[39m store_entrypoint\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    426\u001b[0m         store,\n\u001b[0;32m    427\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[0;32m    434\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\h5netcdf_.py:176\u001b[0m, in \u001b[0;36mH5NetCDFStore.open\u001b[1;34m(cls, filename, mode, format, group, lock, autoclose, invalid_netcdf, phony_dims, decode_vlen_strings)\u001b[0m\n\u001b[0;32m    173\u001b[0m         lock \u001b[38;5;241m=\u001b[39m combine_locks([HDF5_LOCK, get_write_lock(filename)])\n\u001b[0;32m    175\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(h5netcdf\u001b[38;5;241m.\u001b[39mFile, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(manager, group\u001b[38;5;241m=\u001b[39mgroup, mode\u001b[38;5;241m=\u001b[39mmode, lock\u001b[38;5;241m=\u001b[39mlock, autoclose\u001b[38;5;241m=\u001b[39mautoclose)\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\h5netcdf_.py:127\u001b[0m, in \u001b[0;36mH5NetCDFStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# todo: utilizing find_root_and_group seems a bit clunky\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#  making filename available on h5netcdf.Group seems better\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m find_root_and_group(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfilename\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock \u001b[38;5;241m=\u001b[39m ensure_lock(lock)\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\h5netcdf_.py:187\u001b[0m, in \u001b[0;36mH5NetCDFStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire()\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\h5netcdf_.py:179\u001b[0m, in \u001b[0;36mH5NetCDFStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    180\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(\n\u001b[0;32m    181\u001b[0m             root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode, create_group\u001b[38;5;241m=\u001b[39m_h5netcdf_create_group\n\u001b[0;32m    182\u001b[0m         )\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\h5netcdf\\core.py:1522\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, path, mode, invalid_netcdf, phony_dims, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preexisting_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path) \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5py \u001b[38;5;241m=\u001b[39m h5py\n\u001b[1;32m-> 1522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5py\u001b[38;5;241m.\u001b[39mFile(\n\u001b[0;32m   1523\u001b[0m             path, mode, track_order\u001b[38;5;241m=\u001b[39mtrack_order, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1524\u001b[0m         )\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, h5py\u001b[38;5;241m.\u001b[39mFile):\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preexisting_file \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'c:\\Users\\Mattia\\OneDrive\\Documenti\\GitHub\\Data_Analysis\\Data\\ARGO SW2311019A - Coarse gain tune up.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "pump_pars, g_prof, m_avg = plot_everything(\n",
    "    r\"Data/ARGO SW2311019A - Coarse gain tune up.h5\", \n",
    "    r\"Data/ARGO SW2311019A - Fine gain tune up.h5\", \n",
    "    \"ARGO SW2311019A\", \n",
    "    phase_matching_scheme='Dispersion engineering', \n",
    "    top_k=5, w=0.4e9, min_prominence=0.3, cut_off=1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S21_trial = xr.open_dataset(r\"Data/ARGO SW2311019A - Fine gain tune up.h5\", engine='h5netcdf')['S21'].rf.LogMag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massimo, frequenza = fft_on_diff(S21_trial.sel(pump_pars[0]), padded_moving_average(S21_trial.sel(pump_pars[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = best_window(massimo, frequenza)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double smoothing\n",
    "\n",
    "plt.subplots(figsize=[10, 3], dpi=200)\n",
    "#plt.plot(S21_trial[\"Frequency\"].data, S21_trial.sel(pump_pars[0]), color=\"violet\", label=\"Original\")\n",
    "#plt.plot(S21_trial[\"Frequency\"].data, padded_moving_average(S21_trial.sel(pump_pars[4]), w), color=\"red\", label=\"Single smoothing\")\n",
    "plt.plot(S21_trial[\"Frequency\"].data, padded_moving_average(padded_moving_average(S21_trial.sel(pump_pars[4]), w), w), color=\"green\", label=\"Double smoothing\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Frequency / HZ\")\n",
    "plt.ylabel(\"|S21| / dB\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proviamo a fare queste operazioni con crescendo\n",
    "\n",
    "pump_pars_c, g_prof_c, m_avg_c = plot_everything(\n",
    "    r\"Data/CRESCENDO V14W15F1- Coarse gain tune up.h5\", \n",
    "    r\"Data/CRESCENDO V14W15F1- Fine gain tune up.h5\", \n",
    "    \"CRESCENDO V14W15F1\", \n",
    "    phase_matching_scheme='Dispersion engineering', \n",
    "    top_k=5, w=0.4e9, min_prominence=0.3, cut_off=1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crescendo = xr.open_dataset(r\"Data/CRESCENDO V14W15F1- Fine gain tune up.h5\", engine=\"h5netcdf\")['S21'].rf.LogMag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massimo_c, frequenza_c = fft_on_diff(crescendo.sel(pump_pars_c[4]), padded_moving_average(crescendo.sel(pump_pars_c[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_c = best_window(massimo_c, frequenza_c)\n",
    "print(w_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusions\n",
    "#La finestra più adatta per approssimare i profili sembra essere window_opt = 11\n",
    "#Con questa scelta, la costante di proporzionalità alpha si può prendere circa pari a 1/50 (0.02)\n",
    "\n",
    "#quindi la formula finale per la scelta della finestra è data da:\n",
    "#window_opt = alpha * massimo * frequenza / 16e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eventuali aggiunte per smussare ancora il profilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double smoothing\n",
    "\n",
    "plt.subplots(figsize=[10, 3], dpi=200)\n",
    "#plt.plot(crescendo[\"Frequency\"].data, crescendo.sel(pump_pars_c[3]), color=\"violet\", label=\"Original\")\n",
    "#plt.plot(crescendo[\"Frequency\"].data, padded_moving_average(crescendo.sel(pump_pars_c[3]), w_c), color=\"red\", label=\"Single smoothing\")\n",
    "plt.plot(crescendo[\"Frequency\"].data, padded_moving_average(padded_moving_average(crescendo.sel(pump_pars_c[4]), w_c), w_c), color=\"green\", label=\"Double smoothing\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Frequency / HZ\")\n",
    "plt.ylabel(\"|S21| / dB\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
